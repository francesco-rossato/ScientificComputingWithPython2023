{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy.random as npr\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. **Text files**\n",
    "\n",
    "Perform the following operations on plain `txt` files:\n",
    "\n",
    "+ create a list of integrer numbers and then save it to a text file named `data_int.txt`. Run the `cat` command to print the content of the file.\n",
    "+ create a matrix of 5x5 floats and then save it to a text file named `data_float.txt`. Use the `cat` command to print the content of the file.\n",
    "+ load the `txt` file of the previous point and convert it to a `csv` file by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToCSV(srcFileName, destFileName):\n",
    "    with open(srcFileName, 'r') as inFile, open(destFileName, 'w') as outFile:\n",
    "        line = inFile.read()\n",
    "        line = line.replace(\" \", \",\")\n",
    "        outFile.write(line)\n",
    "\n",
    "# create the list\n",
    "anIntList = [x for x in range(10)]\n",
    "aFloatList = np.linspace(0,1,25).reshape(5,5)\n",
    "intFileName = \"data/data_int.txt\"\n",
    "floatFileName = \"data/data_float.txt\"\n",
    "\n",
    "# saving to file\n",
    "with open(intFileName, 'w') as outFile:\n",
    "    for n in range(len(anIntList)-1): outFile.write(str(anIntList[n]) + ' ')\n",
    "    outFile.write(str(anIntList[-1]))\n",
    "    \n",
    "with open(floatFileName, 'w') as outFile:\n",
    "    for n in range(len(aFloatList)):\n",
    "        for m in range(len(aFloatList[n]) -1):\n",
    "            outFile.write(str(aFloatList[n][m]) + ' ')\n",
    "        outFile.write(str(aFloatList[n][-1]))\n",
    "        outFile.write(\"\\n\")\n",
    "\n",
    "# printing the two files\n",
    "print(\"integer list from file:\")\n",
    "!cat ./data/data_int.txt\n",
    "print()\n",
    "print(\"\\nfloat matrix from file:\")\n",
    "!cat ./data/data_float.txt\n",
    "\n",
    "# converting to CSV and printing the results\n",
    "convertToCSV(intFileName, \"data_int.csv\")\n",
    "convertToCSV(floatFileName, \"data_float.csv\")\n",
    "print(\"\\ninteger CSV from file:\")\n",
    "!cat ./data/data_int.csv\n",
    "print()\n",
    "print(\"\\nfloat CSV from file:\")\n",
    "!cat ./data/data_float.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. **JSON files**\n",
    "\n",
    "Load the file `user_data.json`, which can be found at:\n",
    "\n",
    "- https://www.dropbox.com/s/sz5klcdpckc39hd/user_data.json\n",
    "\n",
    "and filter the data by the \"CreditCardType\" when it equals to \"American Express\". Than save the data to a new CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://www.dropbox.com/s/sz5klcdpckc39hd/user_data.json -P ./data\n",
    "#!cat data/user_data.json\n",
    "with open('./data/user_data.json', 'r') as f:\n",
    "    data= pd.read_json(f)\n",
    "amex = data[data['CreditCardType'] == \"American Express\"]\n",
    "amex.to_csv('./data/amex_customers.csv')\n",
    "\n",
    "#!cat ./data/amex_customers.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. **CSV files with Pandas**\n",
    "\n",
    "Load the file from this url:\n",
    "\n",
    "- https://www.dropbox.com/s/kgshemfgk22iy79/mushrooms_categorized.csv\n",
    "\n",
    "with Pandas. \n",
    "\n",
    "+ explore and print the DataFrame\n",
    "+ calculate, using `groupby()`, the average value of each feature, separately for each class\n",
    "+ save the file in a JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://www.dropbox.com/s/kgshemfgk22iy79/mushrooms_categorized.csv -P data/\n",
    "with open(\"data/mushrooms_categorized.csv\", 'r') as fin:\n",
    "    data = pd.read_csv(fin)\n",
    "data = data.groupby('class').mean()\n",
    "data.to_json(\"data/mushroom_recap.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. **Reading a database**\n",
    "\n",
    "Get the database `sakila.db` from the lecture `06_dataio.ipynb`, and import the table `actors` as a Pandas dataframe. Using the dataframe, count how many actors have a first name that begins with `A`.\n",
    "\n",
    "*Hint:* use the Series `.str` method to apply the Python string methods to the elements of a Series, see [documentation](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. **Reading the credit card numbers**\n",
    "\n",
    "Get the binary file named `credit_card.dat` from this address:\n",
    "\n",
    "- https://www.dropbox.com/s/8m0syw2tkul3dap/credit_card.dat\n",
    "\n",
    "and convert the data into the real credit card number, knowing that:\n",
    "- each line corresponds to a credit card number, which consists of 16 characters (which are numbers in the 0-9 range) divided in 4 blocks, with a whitespace between each block\n",
    "- each character is written using a 6 bit binary representation (including the whitespace)\n",
    "- the final 4 bits of each line are a padding used to determine the end of the line, and can be ignored\n",
    "\n",
    "*Hint*: convert the binary numbers to the decimal representation first, and then use the `chr()` function to convert the latter to a char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://www.dropbox.com/s/8m0syw2tkul3dap/credit_card.dat -P data/\n",
    "#!hexdump data/credit_card.dat\n",
    "\n",
    "with open('data/credit_card.dat', 'rb') as fin:\n",
    "    i = 1\n",
    "    current = \"\"\n",
    "    while True:\n",
    "        if(i == 20):\n",
    "            fin.read(5)\n",
    "            print(current)\n",
    "            current = \"\"\n",
    "            i = 1\n",
    "        else:\n",
    "            chunk = fin.read(6)\n",
    "            if len(chunk) == 0:\n",
    "                break\n",
    "            current = current + str(chr(int(chunk, 2)))\n",
    "            i += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. **Write data to a binary file**\n",
    "\n",
    "a) Start from the `data/data_000637.txt` file that we have used during the previous lectures, and convert it to a binary file according to the format defined below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"images/data_format.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hints*:\n",
    "- Read the first 10 lines using Pandas\n",
    "- Iterate over the DataFrame rows\n",
    "- For every row, \"pack\" the values (features) into a single 64-bit word, according to the format specified above. Use bit-wise shifts and operators to do so.\n",
    "- Write each 64-bit word to a binary file. You can use `struct` in this way:\n",
    "```\n",
    "binary_file.write( struct.pack('<q', word) )\n",
    "```\n",
    "where `word` is the 64-bit word.\n",
    "- Close the file after completing the loop.\n",
    "\n",
    "b) Check that the binary file is correctly written by reading it with the code used in the lecture `06_dataio.ipynb`, and verify that the content of the `txt` and binary files is consistent.\n",
    "\n",
    "c) What is the difference of the size on disk between equivalent `txt` and binary files?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://www.dropbox.com/s/ga9wi6b40cakgae/data_000637.txt -P data/\n",
    "\n",
    "import struct\n",
    "\n",
    "\n",
    "dataIn = pd.read_csv('./data/data_000637.txt', nrows=11)\n",
    "print(\"the original text file reads as follows: \\n\")\n",
    "print(dataIn)\n",
    "\n",
    "# writing the data as text file for comparison\n",
    "with open('data/text_file.txt', mode='w') as ftxt:\n",
    "            ftxt.write(str(dataIn))\n",
    "\n",
    "with open('data/binary_file.dat','wb')as fbin:\n",
    "     for line in dataIn.values:\n",
    "        word = line[0] << 62   #index\n",
    "        word += line[1] << 58  #FPGA number\n",
    "        word += line[2] << 49  #TDC channel\n",
    "        word += line[3] << 17  #orbit CNT\n",
    "        word += line[4] << 5   #BX counter\n",
    "        word += line[5] << 0   #TDC meas\n",
    "        fbin.write(struct.pack('<q',word))\n",
    "\n",
    "# this is the code from the lesson to read the data file, it should (and does) have the same output as\n",
    "# the one above\n",
    "\n",
    "import struct, time\n",
    "\n",
    "data = {}\n",
    "\n",
    "with open('data/binary_file.dat', 'rb') as file:\n",
    "    file_content = file.read()\n",
    "    word_counter = 0\n",
    "    word_size = 8 # size of the word in bytes\n",
    "    for i in range(0, len(file_content), word_size):\n",
    "        word_counter += 1\n",
    "        word = struct.unpack('<q', file_content[i : i + word_size])[0] # get an 8-byte word\n",
    "        head     = (word >> 62) & 0x3\n",
    "        fpga     = (word >> 58) & 0xF\n",
    "        tdc_chan = (word >> 49) & 0x1FF\n",
    "        orb_cnt  = (word >> 17) & 0xFFFFFFFF\n",
    "        bx       = (word >> 5 ) & 0xFFF\n",
    "        tdc_meas = (word >> 0 ) & 0x1F\n",
    "        #if i == 0: print ('{0}\\t{1}\\t{2}\\t{3}\\t{4}\\t{5}'.format('HEAD', 'FPGA', 'CHANNEL', 'ORBIT_CNT', 'BX_CNT', 'TDC_MEAS'))\n",
    "        #print('{0}\\t{1}\\t{2}\\t{3}\\t{4}\\t{5}'.format(head, fpga, tdc_chan, orb_cnt, bx, tdc_meas))\n",
    "        entry = {'HEAD' : head, 'FPGA' : fpga, 'CHANNEL' : tdc_chan, 'ORBIT_CNT' : orb_cnt, 'BX_CNT' : bx, 'TDC_MEAS' : tdc_meas}\n",
    "        #df = df.append(entry, ignore_index=True)\n",
    "        data[word_counter] = entry\n",
    "\n",
    "print(\"\\n\\nsaving the file as binary and subsequently reading it with the code presented during the lecture, we obtain:\\n\")\n",
    "df = pd.DataFrame(data).T\n",
    "print(df)\n",
    "\n",
    "print(\"\\nas we can see, both files read correctly.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "print(\"text file size:\",Path('data/text_file.txt').stat().st_size)\n",
    "print(\"bin file size:\",Path('data/binary_file.dat').stat().st_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
